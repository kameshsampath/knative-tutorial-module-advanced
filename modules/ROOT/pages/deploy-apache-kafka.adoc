[[deploy-apache-kafka]]
== Deploying Apache Kafka Cluster

include::_attributes.adoc[]
:strimzi-version: v0.16.2


As part of the upcoming section of this chapter, we will be deploying a <<eventing-source,Knative Source>>, that will respond to Apache Kafka Topic messages(events). Before getting to other exercies, we need to first deploy Apache Kafka inside in your Kubernetes cluster. 

The https://operatorhub.io/operator/strimzi-kafka-operator[strimzi] Kubernetes https://kubernetes.io/docs/concepts/extend-kubernetes/operator/[operator] can be used to deploy the Apache Kafka Cluster in your Kubernetes cluster. 

Run the following command to create the `kafka` namespace and deploy Apache Kafka into it:

ifndef::workshop[]
[tabs]
====
kubectl::
+
--
[#eventing-deploy-kafka]
[source,bash,subs="+quotes,attributes+,+macros"]
----
kubectl create namespace kafka &&\
curl -L \
https://github.com/strimzi/strimzi-kafka-operator\
/releases/download/{strimzi-version}/strimzi-cluster-operator-{strimzi-version}.yaml \
  | sed 's/namespace: .*/namespace: kafka/' \
  | kubectl apply -n kafka -f -
----
copyToClipboard::eventing-deploy-kafka[]
--
oc::
+
--
endif::[]\
[#oc-eventing-deploy-kafka]
[source,bash,subs="+quotes,attributes+,+macros"]
----
oc create namespace kafka &&\
curl -L \
https://github.com/strimzi/strimzi-kafka-operator\
/releases/download/{strimzi-version}/strimzi-cluster-operator-{strimzi-version}.yaml \
  | sed 's/namespace: .*/namespace: kafka/' \
  | oc apply -n kafka -f - 
----
copyToClipboard::oc-eventing-deploy-kafka[]
ifndef::workshop[]
--
endif::[]
====

Wait for the strimzi-cluster-operator to be running:

ifndef::workshop[]
[tabs]
====
kubectl::
+
--
[#eventing-watch-kafka-pods]
[source,bash,subs="+quotes,attributes+,+macros"]
----
watch kubectl get pods -n kafka
----
copyToClipboard::eventing-watch-kafka-pods[]
--
oc::
+
--
endif::[]
[#oc-eventing-watch-kafka-pods]
[source,bash,subs="+quotes,attributes+,+macros"]
----
watch oc get pods -n kafka
----
copyToClipboard::oc-eventing-watch-kafka-pods[]
ifndef::workshop[]
--
endif::[]
====

The command should show the following output:

[source,bash,subs="+quotes,attributes+,+macros"]
----
NAME                                        READY STATUS    AGE
strimzi-cluster-operator-85f596bfc7-7dgds   1/1   Running   1m2s
----

The strimzi operator would have installed several Apache Kafka related CRDs which can be used to create Apache Kafka core resources such as a topic, users, connectors etc., you can verify the CRDs that are available by querying `api-resources`:

ifndef::workshop[]
[tabs]
====
kubectl::
+
--
[#eventing-watch-kafka-res]
[source,bash,subs="+quotes,attributes+,+macros"]
----
kubectl api-resources --api-group='kafka.strimzi.io'
----
copyToClipboard::eventing-watch-kafka-res[]
--
oc::
+
--
endif::[]
[#oc-eventing-watch-kafka-res]
[source,bash,subs="+quotes,attributes+,+macros"]
----
oc api-resources --api-group='kafka.strimzi.io'
----
copyToClipboard::oc-eventing-watch-kafka-res[]
ifndef::workshop[]
--
endif::[]
====

The command should show the following output:

[source,bash,subs="+quotes,attributes+,+macros"]
----
kafkabridges.kafka.strimzi.io                        2019-12-28T14:53:14Z
kafkaconnects.kafka.strimzi.io                       2019-12-28T14:53:14Z
kafkaconnects2is.kafka.strimzi.io                    2019-12-28T14:53:14Z
kafkamirrormakers.kafka.strimzi.io                   2019-12-28T14:53:14Z
kafkas.kafka.strimzi.io                              2019-12-28T14:53:14Z
kafkatopics.kafka.strimzi.io                         2019-12-28T14:53:14Z
kafkausers.kafka.strimzi.io                          2019-12-28T14:53:14Z
----

Now with the Apache Kafka operator running, you can deploy and verify a single node Apache Kakfa cluster by running the command:

ifndef::workshop[]
[tabs]
====
kubectl::
+
--
[#create-kafka-cluster]
[source,bash,subs="+quotes,attributes+,+macros"]
----
kubectl -n kafka apply -f kafka-broker-my-cluster.yaml
----
copyToClipboard::create-kafka-cluster[]

Watch the Kafka cluster deployment:

[#watch-kafka-cluster]
[source,bash,subs="+quotes,attributes+,+macros"]
----
watch kubectl get pods -n kafka
----
copyToClipboard::watch-kafka-cluster[]
--
oc::
+
--
endif::[]
[#oc-create-kafka-cluster]
[source,bash,subs="+quotes,attributes+,+macros"]
----
oc -n kafka apply -f kafka-broker-my-cluster.yaml
----
copyToClipboard::oc-create-kafka-cluster[]

Watch the Kafka cluster deployment:

[#oc-watch-kafka-cluster]
[source,bash,subs="+quotes,attributes+,+macros"]
----
oc kubectl get pods -n kafka
----
copyToClipboard::oc-watch-kafka-cluster[]
ifndef::workshop[]
--
endif::[]
====

Watch the `kafka` namespace for the cluster deployment:

[source,bash,subs="+quotes,attributes+,+macros"]
----
NAME                                         READY  STATUS   AGE
my-cluster-entity-operator-7d677bdf7b-jpws7  3/3    Running  85s
my-cluster-kafka-0                           2/2    Running  110s
my-cluster-zookeeper-0                       2/2    Running  2m22s
strimzi-cluster-operator-85f596bfc7-7dgds    1/1    Running  4m22s
----

The Kubernetes CRD resource `$TUTORIAL_HOME/eventing/kafka-broker-my-cluster.yaml`, will deploy a single *Zookeeper*, *Kafka Broker* and a *Entity-Operator*.  The *Entity-Operator* is responsible for managing different custom resources such as KafkaTopic and KafkaUser.

Now that you have an Apache Kafka cluster deployed, you can create a Kafka Topic using the KafkaTopic CRD, the following listing shows how to create a Kafka Topic `my-topic`:

.Create Kafka Topic my-topic
[source,yaml]
----
apiVersion: kafka.strimzi.io/v1alpha1
kind: KafkaTopic
metadata:
  name: my-topic
  labels:
    strimzi.io/cluster: my-cluster
spec:
  partitions: 10 # <1>
  replicas: 1
----

<1> Partitions 10 allows for more concurrent scale-out of sink pods.  In theory, up to 10 pods will scale-up if there are enough messages flowing through the Kafka topic.

[NOTE]
====
You can choose to skip the manual pre-creation of a KafkaTopic but the automatically generated topics will have partitions set to 1 by default.
====

[[create-kafka-topic]]
=== Create Kafka Topic

ifndef::workshop[]
[tabs]
====
kubectl::
+
--

[#create-kakfa-topic]
[source,bash,subs="+quotes,attributes+,+macros"]
----
kubectl -n kafka create -f kafka-topic-my-topic.yaml
----
copyToClipboard::create-kakfa-topic[]

Verify the created topic:

[#verify-create-kakfa-topic]
[source,bash,subs="+quotes,attributes+,+macros"]
----
kubectl -n kafka  get kafkatopics
----
copyToClipboard::verify-create-kakfa-topic[]
--
oc::
+
--
endif::[]

[#oc-create-kakfa-topic]
[source,bash,subs="+quotes,attributes+,+macros"]
----
kubectl -n kafka create -f kafka-topic-my-topic.yaml
----
copyToClipboard::oc-create-kakfa-topic[]

Verify the created topic:

[#oc-verify-create-kakfa-topic]
[source,bash,subs="+quotes,attributes+,+macros"]
----
kubectl -n kafka  get kafkatopics
----
copyToClipboard::oc-verify-create-kakfa-topic[]
ifndef::workshop[]
--
endif::[]
====

The verify command should show the following output:

[source,bash]
----
NAME       PARTITIONS   REPLICATION FACTOR
my-topic   10           1
----

Verify that your Kafka Topic is working correctly by connecting a simple producer, consumer and creating some test messages.  The sample code repository includes a script for producing Kafka messages called `kafka-producer.sh`.  Execute the script and type in "one", "two", "three".  Hitting enter/return after each string:

[[kafka-producer]]
=== Producer

[#run-kafka-producer]
[source,bash,subs="+quotes,attributes+,+macros"]
----
$TUTORIAL_HOME/bin/kafka-producer.sh
----
copyToClipboard::run-kafka-producer[]

On the terminal prompt try entering texts like:

[source,bash,subs="+quotes,attributes+,+macros"]
----
>one
>two
>three
----

[[kafka-consumer]]
=== Consumer

You should also leverage the sample code repository's `kafka-consumer.sh` script to see the message flow through the topic, open a new terminal and run:

[#run-kafka-consumer]
[source,bash,subs="+quotes,attributes+,+macros"]
----
$ *$TUTORIAL_HOME/bin/kafka-consumer.sh*
----
copyToClipboard::run-kafka-consumer[]

On the consumer terminal prompt you will receive texts like:

[source,bash,subs="+quotes,attributes+,+macros"]
----
>one
>two
>three
----

You can use kbd:[Ctrl-c] to stop producer & consumer interaction and their associated pods.
